{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0967517a",
   "metadata": {},
   "source": [
    "# RAG Application - Complete Interactive Notebook\n",
    "## PDF-based Retrieval Augmented Generation System\n",
    "\n",
    "This notebook provides an interactive interface for:\n",
    "- üìÑ PDF document upload and processing\n",
    "- üîç Vector-based document storage using FAISS\n",
    "- üß† Semantic search and retrieval with sentence transformers\n",
    "- üí¨ Question answering with Ollama LLM\n",
    "- üìä Document management and analytics\n",
    "\n",
    "## üéØ Prerequisites\n",
    "- Ollama installed and running\n",
    "- Python 3.8+\n",
    "- Model: llama2 (or your preferred model)\n",
    "\n",
    "**Based on files:** controller.py, rag_engine.py, server.py, utils.py, requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea643ed",
   "metadata": {},
   "source": [
    "## 1. Install Dependencies\n",
    "Run this cell first to install all required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9f50fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install all required packages\n",
    "!pip install fastapi==0.109.0 -q\n",
    "!pip install uvicorn==0.27.0 -q\n",
    "!pip install PyPDF2==3.0.1 -q\n",
    "!pip install sentence-transformers==2.3.1 -q\n",
    "!pip install faiss-cpu==1.7.4 -q\n",
    "!pip install numpy==1.26.4 -q\n",
    "!pip install ollama==0.1.6 -q\n",
    "!pip install python-multipart==0.0.6 -q\n",
    "!pip install reportlab==4.0.9 -q\n",
    "!pip install pandas==2.2.0 -q\n",
    "!pip install matplotlib==3.8.3 -q\n",
    "!pip install ipywidgets==8.1.1 -q\n",
    "\n",
    "print(\"‚úÖ All dependencies installed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a41c3e",
   "metadata": {},
   "source": [
    "## 2. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2abd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import uuid\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Dict, Any, Optional\n",
    "from PyPDF2 import PdfReader\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "import ollama\n",
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas\n",
    "from IPython.display import display, HTML, clear_output\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf398bbf",
   "metadata": {},
   "source": [
    "## 3. Utility Functions (from utils.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a632d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TemplateManager:\n",
    "    \"\"\"Simple template manager for RAG prompts\"\"\"\n",
    "    \n",
    "    # Prompt Templates\n",
    "    DEFAULT = \"\"\"Based on the following context, answer the question.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer:\"\"\"\n",
    "    \n",
    "    DETAILED = \"\"\"You are a helpful assistant. Use the following context to answer the question in detail.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Provide a comprehensive answer:\"\"\"\n",
    "    \n",
    "    CONCISE = \"\"\"Answer briefly using only the context provided.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Brief Answer:\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def get(template_type: str = \"default\") -> str:\n",
    "        \"\"\"Get template by type\"\"\"\n",
    "        templates = {\n",
    "            \"default\": TemplateManager.DEFAULT,\n",
    "            \"detailed\": TemplateManager.DETAILED,\n",
    "            \"concise\": TemplateManager.CONCISE\n",
    "        }\n",
    "        return templates.get(template_type, TemplateManager.DEFAULT)\n",
    "\n",
    "\n",
    "def process_pdf_file(pdf_content: bytes, chunk_size: int = 500) -> List[str]:\n",
    "    \"\"\"Process PDF file and extract text chunks\"\"\"\n",
    "    pdf_file = io.BytesIO(pdf_content)\n",
    "    pdf_reader = PdfReader(pdf_file)\n",
    "    \n",
    "    # Extract text from all pages\n",
    "    text = \"\"\n",
    "    for page in pdf_reader.pages:\n",
    "        text += page.extract_text()\n",
    "    \n",
    "    # Split into chunks\n",
    "    chunks = []\n",
    "    words = text.split()\n",
    "    \n",
    "    for i in range(0, len(words), chunk_size):\n",
    "        chunk = \" \".join(words[i:i + chunk_size])\n",
    "        chunks.append(chunk)\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "print('‚úÖ Utility functions loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d59384",
   "metadata": {},
   "source": [
    "## 4. RAG Engine (from rag_engine.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa602371",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGEngine:\n",
    "    def __init__(self, model_name=\"all-MiniLM-L6-v2\", llm_model=\"llama3.2\"):\n",
    "        print(f\"üîÑ Initializing RAG Engine with FAISS...\")\n",
    "        self.embedding_model = SentenceTransformer(model_name)\n",
    "        self.llm_model = llm_model\n",
    "        self.dimension = 384  # all-MiniLM-L6-v2 embedding size\n",
    "        self.index = faiss.IndexFlatL2(self.dimension)\n",
    "        self.chunks = []\n",
    "        self.metadata = []\n",
    "        print(f\"‚úÖ RAG Engine initialized with FAISS\")\n",
    "    \n",
    "    def add_document(self, doc_id: str, content: str, filename: str):\n",
    "        \"\"\"Add a document chunk to FAISS vector store\"\"\"\n",
    "        # Generate embedding\n",
    "        embedding = self.embedding_model.encode([content])[0]\n",
    "        \n",
    "        # Add to FAISS index\n",
    "        self.index.add(np.array([embedding], dtype=np.float32))\n",
    "        \n",
    "        # Store chunk and metadata\n",
    "        self.chunks.append(content)\n",
    "        self.metadata.append({\n",
    "            'id': doc_id,\n",
    "            'filename': filename\n",
    "        })\n",
    "        \n",
    "        print(f\"‚úÖ Added chunk from: {filename} (Total chunks: {len(self.chunks)})\")\n",
    "    \n",
    "    def search(self, query: str, top_k: int = 3, filter_filenames: List[str] = None) -> List[Dict]:\n",
    "        \"\"\"Search for relevant chunks based on query with optional filename filtering\"\"\"\n",
    "        if not self.chunks:\n",
    "            return []\n",
    "        \n",
    "        # Encode query\n",
    "        query_embedding = self.embedding_model.encode([query])\n",
    "        query_vector = np.array(query_embedding, dtype=np.float32)\n",
    "        \n",
    "        # If filtering, search more results to ensure we get enough after filtering\n",
    "        search_k = top_k if not filter_filenames else min(len(self.chunks), top_k * 3)\n",
    "        \n",
    "        # Search in FAISS\n",
    "        distances, indices = self.index.search(query_vector, min(search_k, len(self.chunks)))\n",
    "        \n",
    "        results = []\n",
    "        for i, idx in enumerate(indices[0]):\n",
    "            if idx < len(self.chunks):\n",
    "                # Filter by filename if specified\n",
    "                if filter_filenames and self.metadata[idx]['filename'] not in filter_filenames:\n",
    "                    continue\n",
    "                \n",
    "                # Convert L2 distance to similarity score (0-1)\n",
    "                similarity = 1 / (1 + distances[0][i])\n",
    "                results.append({\n",
    "                    'id': self.metadata[idx]['id'],\n",
    "                    'filename': self.metadata[idx]['filename'],\n",
    "                    'content': self.chunks[idx],\n",
    "                    'score': float(similarity)\n",
    "                })\n",
    "                \n",
    "                # Stop when we have enough results\n",
    "                if len(results) >= top_k:\n",
    "                    break\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def search_with_id_filter(self, query: str, top_k: int = 3, filter_filenames: List[str] = None) -> List[Dict]:\n",
    "        \"\"\"Search with FAISS ID filtering for better performance\"\"\"\n",
    "        if not self.chunks:\n",
    "            return []\n",
    "        \n",
    "        # Encode query\n",
    "        query_embedding = self.embedding_model.encode([query])\n",
    "        query_vector = np.array(query_embedding, dtype=np.float32)\n",
    "        \n",
    "        if filter_filenames:\n",
    "            # Create ID selector for filtering\n",
    "            valid_ids = [i for i, meta in enumerate(self.metadata) \n",
    "                         if meta['filename'] in filter_filenames]\n",
    "        \n",
    "            if not valid_ids:\n",
    "                return []\n",
    "        \n",
    "            # Use IDSelectorBatch for filtering\n",
    "            id_selector = faiss.IDSelectorBatch(valid_ids)\n",
    "            params = faiss.SearchParametersIVF(sel=id_selector)\n",
    "            distances, indices = self.index.search(query_vector, top_k, params=params)\n",
    "        else:\n",
    "            distances, indices = self.index.search(query_vector, min(top_k, len(self.chunks)))\n",
    "        \n",
    "        results = []\n",
    "        for i, idx in enumerate(indices[0]):\n",
    "            if idx >= 0 and idx < len(self.chunks):\n",
    "                similarity = 1 / (1 + distances[0][i])\n",
    "                results.append({\n",
    "                    'id': self.metadata[idx]['id'],\n",
    "                    'filename': self.metadata[idx]['filename'],\n",
    "                    'content': self.chunks[idx],\n",
    "                    'score': float(similarity)\n",
    "                })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def create_prompt(self, query: str, context: str, template_type: str = \"default\") -> str:\n",
    "        \"\"\"Create a prompt for the LLM from query and context\"\"\"\n",
    "        template = TemplateManager.get(template_type)\n",
    "        return template.format(context=context, query=query)\n",
    "    \n",
    "    def generate_answer(self, query: str, top_k: int = 3, template_type: str = \"default\", filter_filenames: List[str] = None) -> Dict:\n",
    "        \"\"\"Generate answer using RAG with optional document filtering\"\"\"\n",
    "        # Search for relevant chunks with optional filtering\n",
    "        results = self.search(query, top_k, filter_filenames=filter_filenames)\n",
    "        \n",
    "        if not results:\n",
    "            filter_msg = f\" in documents: {', '.join(filter_filenames)}\" if filter_filenames else \"\"\n",
    "            return {\n",
    "                'answer': f'No relevant information found{filter_msg}.',\n",
    "                'sources': [],\n",
    "                'filenames': [],\n",
    "                'num_sources': 0\n",
    "            }\n",
    "        \n",
    "        # Build context from results\n",
    "        context = \"\\n\\n\".join([r['content'] for r in results])\n",
    "        \n",
    "        # Create prompt using template manager\n",
    "        prompt = self.create_prompt(query, context, template_type)\n",
    "        \n",
    "        # Generate answer using Ollama\n",
    "        try:\n",
    "            response = ollama.generate(\n",
    "                model=self.llm_model,\n",
    "                prompt=prompt\n",
    "            )\n",
    "            answer = response['response']\n",
    "        except Exception as e:\n",
    "            answer = f\"Error generating answer: {str(e)}\"\n",
    "        \n",
    "        return {\n",
    "            'answer': answer,\n",
    "            'sources': [r['content'][:200] + '...' for r in results],\n",
    "            'filenames': list(set([r['filename'] for r in results])),\n",
    "            'num_sources': len(results)\n",
    "        }\n",
    "    \n",
    "    def get_all_documents(self) -> List[Dict]:\n",
    "        \"\"\"Get all stored chunks\"\"\"\n",
    "        return [\n",
    "            {\n",
    "                'id': meta['id'],\n",
    "                'filename': meta['filename'],\n",
    "                'content': content\n",
    "            }\n",
    "            for meta, content in zip(self.metadata, self.chunks)\n",
    "        ]\n",
    "    \n",
    "    def save_state(self, filepath: str = \"data/rag_state.pkl\"):\n",
    "        \"\"\"Save FAISS index and data to disk\"\"\"\n",
    "        os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "        \n",
    "        # Save FAISS index\n",
    "        faiss.write_index(self.index, filepath.replace('.pkl', '.faiss'))\n",
    "        \n",
    "        # Save metadata and chunks\n",
    "        state = {\n",
    "            'chunks': self.chunks,\n",
    "            'metadata': self.metadata\n",
    "        }\n",
    "        with open(filepath, 'wb') as f:\n",
    "            pickle.dump(state, f)\n",
    "        \n",
    "        print(f\"üíæ Saved state to {filepath}\")\n",
    "    \n",
    "    def load_state(self, filepath: str = \"data/rag_state.pkl\"):\n",
    "        \"\"\"Load FAISS index and data from disk\"\"\"\n",
    "        faiss_path = filepath.replace('.pkl', '.faiss')\n",
    "        \n",
    "        if os.path.exists(filepath) and os.path.exists(faiss_path):\n",
    "            # Load FAISS index\n",
    "            self.index = faiss.read_index(faiss_path)\n",
    "            \n",
    "            # Load metadata and chunks\n",
    "            with open(filepath, 'rb') as f:\n",
    "                state = pickle.load(f)\n",
    "                self.chunks = state['chunks']\n",
    "                self.metadata = state['metadata']\n",
    "            \n",
    "            print(f\"üìÇ Loaded {len(self.chunks)} chunks from {filepath}\")\n",
    "            return True\n",
    "        return False\n",
    "    \n",
    "    def clear(self):\n",
    "        \"\"\"Clear all data\"\"\"\n",
    "        self.index = faiss.IndexFlatL2(self.dimension)\n",
    "        self.chunks = []\n",
    "        self.metadata = []\n",
    "        print(\"üóëÔ∏è Cleared all data\")\n",
    "\n",
    "print('‚úÖ RAG Engine class loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571dbd86",
   "metadata": {},
   "source": [
    "## 5. Controller (from controller.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69be9294",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class RAGController:\n",
    "    \"\"\"Controller for RAG operations\"\"\"\n",
    "    \n",
    "    def __init__(self, llm_model: str = \"llama2\"):\n",
    "        self.rag = RAGEngine(llm_model=llm_model)\n",
    "        self.rag.load_state()\n",
    "    \n",
    "    def upload_pdf(self, pdf_content: bytes, filename: str) -> Dict[str, Any]:\n",
    "        \"\"\"Process and store PDF content\"\"\"\n",
    "        # Validate file extension\n",
    "        if not filename.endswith('.pdf'):\n",
    "            raise ValueError(\"Only PDF files are allowed\")\n",
    "        \n",
    "        # Process PDF and get chunks\n",
    "        chunks = process_pdf_file(pdf_content)\n",
    "        \n",
    "        # Add each chunk to RAG engine\n",
    "        for chunk in chunks:\n",
    "            doc_id = str(uuid.uuid4())\n",
    "            self.rag.add_document(doc_id, chunk, filename)\n",
    "        \n",
    "        # Save state\n",
    "        self.rag.save_state()\n",
    "        \n",
    "        return {\n",
    "            \"message\": \"PDF processed successfully\",\n",
    "            \"filename\": filename,\n",
    "            \"chunks_created\": len(chunks),\n",
    "            \"total_chunks\": len(self.rag.chunks)\n",
    "        }\n",
    "    \n",
    "    def query_documents(self, query: str, top_k: int = 3, template_type: str = \"default\", \n",
    "                       filter_filenames: Optional[List[str]] = None) -> Dict[str, Any]:\n",
    "        \"\"\"Query the RAG system with optional document filtering\"\"\"\n",
    "        if len(self.rag.chunks) == 0:\n",
    "            raise ValueError(\"No documents uploaded yet\")\n",
    "        \n",
    "        # Validate filter_filenames if provided\n",
    "        if filter_filenames:\n",
    "            available_docs = self.get_document_list()\n",
    "            invalid_docs = [f for f in filter_filenames if f not in available_docs]\n",
    "            if invalid_docs:\n",
    "                raise ValueError(f\"Documents not found: {', '.join(invalid_docs)}\")\n",
    "        \n",
    "        result = self.rag.generate_answer(query, top_k, template_type, filter_filenames)\n",
    "        return result\n",
    "    \n",
    "    def get_stats(self) -> Dict[str, Any]:\n",
    "        \"\"\"Get statistics about the RAG system\"\"\"\n",
    "        return {\n",
    "            \"total_chunks\": len(self.rag.chunks),\n",
    "            \"total_documents\": len(set([m['filename'] for m in self.rag.metadata])),\n",
    "            \"index_size\": self.rag.index.ntotal\n",
    "        }\n",
    "    \n",
    "    def get_document_list(self) -> List[str]:\n",
    "        \"\"\"Get list of all uploaded documents\"\"\"\n",
    "        if not self.rag.metadata:\n",
    "            return []\n",
    "        return list(set([m['filename'] for m in self.rag.metadata]))\n",
    "    \n",
    "    def get_document_details(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"Get detailed information about each document\"\"\"\n",
    "        if not self.rag.metadata:\n",
    "            return []\n",
    "        \n",
    "        doc_info = {}\n",
    "        for meta in self.rag.metadata:\n",
    "            filename = meta['filename']\n",
    "            if filename not in doc_info:\n",
    "                doc_info[filename] = {\n",
    "                    'filename': filename,\n",
    "                    'chunk_count': 0\n",
    "                }\n",
    "            doc_info[filename]['chunk_count'] += 1\n",
    "        \n",
    "        return list(doc_info.values())\n",
    "    \n",
    "    def get_document_chunks(self, filename: str) -> Dict[str, Any]:\n",
    "        \"\"\"Get all chunks from a specific document\"\"\"\n",
    "        chunks = [\n",
    "            {\n",
    "                'id': meta['id'],\n",
    "                'content': content,\n",
    "                'preview': content[:200] + '...' if len(content) > 200 else content\n",
    "            }\n",
    "            for meta, content in zip(self.rag.metadata, self.rag.chunks)\n",
    "            if meta['filename'] == filename\n",
    "        ]\n",
    "        \n",
    "        if not chunks:\n",
    "            raise ValueError(f\"Document not found: {filename}\")\n",
    "        \n",
    "        return {\n",
    "            'filename': filename,\n",
    "            'chunk_count': len(chunks),\n",
    "            'chunks': chunks\n",
    "        }\n",
    "    \n",
    "    def delete_document(self, filename: str) -> Dict[str, Any]:\n",
    "        \"\"\"Delete a specific document and its chunks\"\"\"\n",
    "        if filename not in self.get_document_list():\n",
    "            raise ValueError(f\"Document not found: {filename}\")\n",
    "        \n",
    "        # Count chunks before deletion\n",
    "        chunks_before = len(self.rag.chunks)\n",
    "        \n",
    "        # Filter out chunks from the specified document\n",
    "        new_chunks = []\n",
    "        new_metadata = []\n",
    "        for meta, chunk in zip(self.rag.metadata, self.rag.chunks):\n",
    "            if meta['filename'] != filename:\n",
    "                new_chunks.append(chunk)\n",
    "                new_metadata.append(meta)\n",
    "        \n",
    "        # Rebuild FAISS index\n",
    "        self.rag.chunks = new_chunks\n",
    "        self.rag.metadata = new_metadata\n",
    "        self.rag.index = faiss.IndexFlatL2(self.rag.dimension)\n",
    "        \n",
    "        # Re-add all remaining chunks to index\n",
    "        if new_chunks:\n",
    "            embeddings = self.rag.embedding_model.encode(new_chunks)\n",
    "            self.rag.index.add(np.array(embeddings, dtype=np.float32))\n",
    "        \n",
    "        # Save state\n",
    "        self.rag.save_state()\n",
    "        \n",
    "        chunks_deleted = chunks_before - len(new_chunks)\n",
    "        \n",
    "        return {\n",
    "            \"message\": f\"Document '{filename}' deleted successfully\",\n",
    "            \"chunks_deleted\": chunks_deleted,\n",
    "            \"remaining_chunks\": len(new_chunks)\n",
    "        }\n",
    "    \n",
    "    def clear_all(self) -> Dict[str, str]:\n",
    "        \"\"\"Clear all data from the system\"\"\"\n",
    "        self.rag.clear()\n",
    "        return {\"message\": \"All data cleared\"}\n",
    "    \n",
    "    def has_documents(self) -> bool:\n",
    "        \"\"\"Check if any documents are loaded\"\"\"\n",
    "        return len(self.rag.chunks) > 0\n",
    "\n",
    "print('‚úÖ RAG Controller class loaded!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43ce7f4",
   "metadata": {},
   "source": [
    "## 6. Initialize RAG System\n",
    "\n",
    "**Important:** Make sure Ollama is installed and running with the llama2 model.\n",
    "\n",
    "Install Ollama: https://ollama.ai/\n",
    "\n",
    "Pull model:\n",
    "\n",
    "ollama pull llama2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f60344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the RAG Controller\n",
    "controller = RAGController(llm_model=\"llama2\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ RAG System Initialized!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Display current stats\n",
    "stats = controller.get_stats()\n",
    "print(f\"\\nüìä Current Statistics:\")\n",
    "print(f\"  - Total Documents: {stats['total_documents']}\")\n",
    "print(f\"  - Total Chunks: {stats['total_chunks']}\")\n",
    "print(f\"  - Index Size: {stats['index_size']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea78d106",
   "metadata": {},
   "source": [
    "## 7. Create Sample PDF Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263215c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sample_pdf(filename: str, title: str, content: str):\n",
    "    \"\"\"Create a sample PDF file for testing\"\"\"\n",
    "    c = canvas.Canvas(filename, pagesize=letter)\n",
    "    width, height = letter\n",
    "    \n",
    "    # Add title\n",
    "    c.setFont(\"Helvetica-Bold\", 16)\n",
    "    c.drawString(50, height - 50, title)\n",
    "    \n",
    "    # Add content\n",
    "    c.setFont(\"Helvetica\", 11)\n",
    "    text_object = c.beginText(50, height - 100)\n",
    "    \n",
    "    # Split content into lines and wrap\n",
    "    lines = content.split('\\n')\n",
    "    for line in lines:\n",
    "        if len(line) > 85:\n",
    "            words = line.split()\n",
    "            current_line = \"\"\n",
    "            for word in words:\n",
    "                if len(current_line + word) < 85:\n",
    "                    current_line += word + \" \"\n",
    "                else:\n",
    "                    text_object.textLine(current_line.strip())\n",
    "                    current_line = word + \" \"\n",
    "            if current_line:\n",
    "                text_object.textLine(current_line.strip())\n",
    "        else:\n",
    "            text_object.textLine(line)\n",
    "    \n",
    "    c.drawText(text_object)\n",
    "    c.save()\n",
    "    print(f\"‚úÖ Created: {filename}\")\n",
    "\n",
    "# Create sample PDFs directory\n",
    "os.makedirs(\"sample_pdfs\", exist_ok=True)\n",
    "\n",
    "# Sample content\n",
    "ai_content = \"\"\"Artificial Intelligence (AI) Overview\n",
    "\n",
    "Artificial Intelligence is the simulation of human intelligence processes by machines, \n",
    "especially computer systems. These processes include learning, reasoning, and self-correction.\n",
    "\n",
    "Key Applications:\n",
    "- Natural Language Processing (NLP)\n",
    "- Computer Vision and Image Recognition\n",
    "- Robotics and Autonomous Systems\n",
    "- Expert Systems and Decision Support\n",
    "- Speech Recognition and Synthesis\n",
    "\n",
    "Machine Learning is a subset of AI that provides systems the ability to automatically \n",
    "learn and improve from experience without being explicitly programmed.\n",
    "\n",
    "Deep Learning is a subset of machine learning based on artificial neural networks.\n",
    "\"\"\"\n",
    "\n",
    "python_content = \"\"\"Python Programming Language Guide\n",
    "\n",
    "Python is a high-level, interpreted programming language known for its simplicity \n",
    "and readability. Created by Guido van Rossum and first released in 1991.\n",
    "\n",
    "Key Features:\n",
    "- Easy to learn and use with clean syntax\n",
    "- Extensive standard library\n",
    "- Cross-platform compatibility\n",
    "- Strong community support\n",
    "\n",
    "Popular Use Cases:\n",
    "1. Web Development (Django, Flask, FastAPI)\n",
    "2. Data Science and Machine Learning\n",
    "3. Automation and Scripting\n",
    "\"\"\"\n",
    "\n",
    "faiss_content = \"\"\"FAISS: Facebook AI Similarity Search\n",
    "\n",
    "FAISS is a library for efficient similarity search and clustering of dense vectors.\n",
    "\n",
    "Key Features:\n",
    "- Fast similarity search in high-dimensional spaces\n",
    "- Supports billions of vectors\n",
    "- GPU acceleration available\n",
    "- Multiple index types for different use cases\n",
    "\"\"\"\n",
    "\n",
    "# Create the PDFs\n",
    "create_sample_pdf(\"sample_pdfs/ai_overview.pdf\", \"Artificial Intelligence Overview\", ai_content)\n",
    "create_sample_pdf(\"sample_pdfs/python_guide.pdf\", \"Python Programming Guide\", python_content)\n",
    "create_sample_pdf(\"sample_pdfs/faiss_guide.pdf\", \"FAISS Library Guide\", faiss_content)\n",
    "\n",
    "print(\"\\n‚úÖ Sample PDFs created in 'sample_pdfs' directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62be571",
   "metadata": {},
   "source": [
    "## 8. Upload PDF Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac37a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_pdf_from_file(filepath: str):\n",
    "    \"\"\"Upload a PDF file to the RAG system\"\"\"\n",
    "    try:\n",
    "        with open(filepath, 'rb') as f:\n",
    "            pdf_content = f.read()\n",
    "        \n",
    "        filename = os.path.basename(filepath)\n",
    "        result = controller.upload_pdf(pdf_content, filename)\n",
    "        \n",
    "        print(f\"\\n‚úÖ {result['message']}\")\n",
    "        print(f\"   Filename: {result['filename']}\")\n",
    "        print(f\"   Chunks Created: {result['chunks_created']}\")\n",
    "        print(f\"   Total Chunks in System: {result['total_chunks']}\")\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error uploading PDF: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Upload sample PDFs\n",
    "print(\"üì§ Uploading sample PDFs...\\n\")\n",
    "upload_pdf_from_file(\"sample_pdfs/ai_overview.pdf\")\n",
    "upload_pdf_from_file(\"sample_pdfs/python_guide.pdf\")\n",
    "upload_pdf_from_file(\"sample_pdfs/faiss_guide.pdf\")\n",
    "\n",
    "# Display updated stats\n",
    "stats = controller.get_stats()\n",
    "print(f\"\\nüìä Updated Statistics:\")\n",
    "print(f\"   Total Documents: {stats['total_documents']}\")\n",
    "print(f\"   Total Chunks: {stats['total_chunks']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b671d20b",
   "metadata": {},
   "source": [
    "## 9. List All Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5e8323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of all documents\n",
    "documents = controller.get_document_list()\n",
    "print(f\"üìö Total Documents: {len(documents)}\\n\")\n",
    "\n",
    "for i, doc in enumerate(documents, 1):\n",
    "    print(f\"{i}. {doc}\")\n",
    "\n",
    "# Get detailed information\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Document Details:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "details = controller.get_document_details()\n",
    "if details:\n",
    "    df = pd.DataFrame(details)\n",
    "    display(df)\n",
    "else:\n",
    "    print(\"No documents found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61bff592",
   "metadata": {},
   "source": [
    "## 10. Query Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7019ad31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_rag_system(query: str, top_k: int = 3, template_type: str = \"default\", \n",
    "                     filter_filenames: List[str] = None):\n",
    "    \"\"\"Query the RAG system and display results\"\"\"\n",
    "    try:\n",
    "        print(f\"\\nüîç Query: {query}\")\n",
    "        print(f\"   Top K: {top_k}\")\n",
    "        print(f\"   Template: {template_type}\")\n",
    "        if filter_filenames:\n",
    "            print(f\"   Filtering by: {', '.join(filter_filenames)}\")\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        \n",
    "        result = controller.query_documents(\n",
    "            query=query,\n",
    "            top_k=top_k,\n",
    "            template_type=template_type,\n",
    "            filter_filenames=filter_filenames\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nüí° Answer:\\n{result['answer']}\")\n",
    "        print(f\"\\nüìÑ Sources Used: {result['num_sources']}\")\n",
    "        print(f\"üìÅ Files: {', '.join(result['filenames'])}\")\n",
    "        \n",
    "        if result['sources']:\n",
    "            print(\"\\nüìñ Source Excerpts:\")\n",
    "            for i, source in enumerate(result['sources'], 1):\n",
    "                print(f\"\\n{i}. {source}\")\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Example query\n",
    "query_rag_system(\"What is Artificial Intelligence?\", top_k=3, template_type=\"default\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fbea46",
   "metadata": {},
   "source": [
    "## 11. Query with Document Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59bf3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query only from specific documents\n",
    "query_rag_system(\n",
    "    query=\"What are the key features of Python?\",\n",
    "    top_k=2,\n",
    "    template_type=\"concise\",\n",
    "    filter_filenames=[\"python_guide.pdf\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fbe3db1",
   "metadata": {},
   "source": [
    "## 12. Run Multiple Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7fadd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run multiple queries\n",
    "queries = [\n",
    "    \"What is Machine Learning?\",\n",
    "    \"What are Python's use cases?\",\n",
    "    \"Explain FAISS and its applications\"\n",
    "]\n",
    "\n",
    "results = []\n",
    "for query in queries:\n",
    "    print(\"\\n\" + \"#\"*70)\n",
    "    result = query_rag_system(query, top_k=2, template_type=\"concise\")\n",
    "    if result:\n",
    "        results.append({\n",
    "            'query': query,\n",
    "            'answer': result['answer'][:150] + '...' if len(result['answer']) > 150 else result['answer'],\n",
    "            'sources': result['num_sources'],\n",
    "            'files': ', '.join(result['filenames'])\n",
    "        })\n",
    "\n",
    "# Display summary\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Query Summary:\")\n",
    "print(\"=\"*70)\n",
    "if results:\n",
    "    df_results = pd.DataFrame(results)\n",
    "    display(df_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ed404b",
   "metadata": {},
   "source": [
    "## 13. View Document Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb48948",
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_document_chunks(filename: str, max_display: int = 3):\n",
    "    \"\"\"View chunks from a specific document\"\"\"\n",
    "    try:\n",
    "        result = controller.get_document_chunks(filename)\n",
    "        print(f\"\\nüìÑ Document: {result['filename']}\")\n",
    "        print(f\"üìä Total Chunks: {result['chunk_count']}\")\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        \n",
    "        for i, chunk in enumerate(result['chunks'][:max_display], 1):\n",
    "            print(f\"\\nChunk {i}:\")\n",
    "            print(f\"ID: {chunk['id']}\")\n",
    "            print(f\"Preview: {chunk['preview']}\")\n",
    "            print(\"-\" * 60)\n",
    "        \n",
    "        if result['chunk_count'] > max_display:\n",
    "            print(f\"\\n... and {result['chunk_count'] - max_display} more chunks\")\n",
    "        \n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# View chunks from a document\n",
    "view_document_chunks(\"ai_overview.pdf\", max_display=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce57fafc",
   "metadata": {},
   "source": [
    "## 14. Interactive Query Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18b3b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive widgets\n",
    "query_input = widgets.Textarea(\n",
    "    value='What is Deep Learning?',\n",
    "    placeholder='Enter your question here',\n",
    "    description='Query:',\n",
    "    layout=widgets.Layout(width='90%', height='80px')\n",
    ")\n",
    "\n",
    "top_k_slider = widgets.IntSlider(\n",
    "    value=3,\n",
    "    min=1,\n",
    "    max=10,\n",
    "    step=1,\n",
    "    description='Top K:',\n",
    "    continuous_update=False\n",
    ")\n",
    "\n",
    "template_dropdown = widgets.Dropdown(\n",
    "    options=['default', 'detailed', 'concise'],\n",
    "    value='default',\n",
    "    description='Template:'\n",
    ")\n",
    "\n",
    "# Document filter\n",
    "doc_list = controller.get_document_list()\n",
    "filter_select = widgets.SelectMultiple(\n",
    "    options=['All'] + doc_list,\n",
    "    value=['All'],\n",
    "    description='Filter Docs:',\n",
    "    rows=min(5, len(doc_list) + 1)\n",
    ")\n",
    "\n",
    "query_button = widgets.Button(\n",
    "    description='üîç Search',\n",
    "    button_style='success',\n",
    "    icon='search'\n",
    ")\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "def on_query_button_clicked(b):\n",
    "    with output_area:\n",
    "        clear_output()\n",
    "        filter_files = None if 'All' in filter_select.value else list(filter_select.value)\n",
    "        query_rag_system(\n",
    "            query=query_input.value,\n",
    "            top_k=top_k_slider.value,\n",
    "            template_type=template_dropdown.value,\n",
    "            filter_filenames=filter_files\n",
    "        )\n",
    "\n",
    "query_button.on_click(on_query_button_clicked)\n",
    "\n",
    "# Display widgets\n",
    "display(widgets.VBox([\n",
    "    widgets.HTML(\"<h3>üîç Interactive Query Interface</h3>\"),\n",
    "    query_input,\n",
    "    widgets.HBox([top_k_slider, template_dropdown]),\n",
    "    filter_select,\n",
    "    query_button,\n",
    "    output_area\n",
    "]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86db38d",
   "metadata": {},
   "source": [
    "## 15. System Statistics and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67db0a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and display statistics\n",
    "stats = controller.get_stats()\n",
    "details = controller.get_document_details()\n",
    "\n",
    "print(\"üìä System Statistics\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total Documents: {stats['total_documents']}\")\n",
    "print(f\"Total Chunks: {stats['total_chunks']}\")\n",
    "print(f\"Index Size: {stats['index_size']}\")\n",
    "\n",
    "# Visualize document distribution\n",
    "if details:\n",
    "    df_details = pd.DataFrame(details)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    # Bar chart\n",
    "    ax1.bar(df_details['filename'], df_details['chunk_count'], color='skyblue', edgecolor='navy')\n",
    "    ax1.set_xlabel('Document', fontsize=12)\n",
    "    ax1.set_ylabel('Number of Chunks', fontsize=12)\n",
    "    ax1.set_title('Chunks per Document', fontsize=14, fontweight='bold')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Pie chart\n",
    "    colors = plt.cm.Set3(range(len(df_details)))\n",
    "    ax2.pie(df_details['chunk_count'], labels=df_details['filename'], \n",
    "            autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "    ax2.set_title('Chunk Distribution', fontsize=14, fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Display table\n",
    "    print(\"\\nDocument Details:\")\n",
    "    display(df_details)\n",
    "else:\n",
    "    print(\"\\nNo documents found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e17b99",
   "metadata": {},
   "source": [
    "## 16. Delete Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7aeb753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_document(filename: str):\n",
    "    \"\"\"Delete a document from the system\"\"\"\n",
    "    try:\n",
    "        result = controller.delete_document(filename)\n",
    "        print(f\"\\n‚úÖ {result['message']}\")\n",
    "        print(f\"   Chunks Deleted: {result['chunks_deleted']}\")\n",
    "        print(f\"   Remaining Chunks: {result['remaining_chunks']}\")\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Example: Delete a document (uncomment to use)\n",
    "# delete_document(\"faiss_guide.pdf\")\n",
    "\n",
    "print(\"Delete function ready. Use: delete_document('filename.pdf')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b579062",
   "metadata": {},
   "source": [
    "## 17. Save and Load System State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1572972",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save current state\n",
    "controller.rag.save_state()\n",
    "print(\"üíæ System state saved!\")\n",
    "\n",
    "# To load state (automatically done on initialization)\n",
    "# controller.rag.load_state()\n",
    "# print(\"üìÇ System state loaded!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55dd7a5a",
   "metadata": {},
   "source": [
    "## 18. Clear All Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606abbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear all data (use with caution!)\n",
    "def clear_all_data():\n",
    "    \"\"\"Clear all data from the system\"\"\"\n",
    "    result = controller.clear_all()\n",
    "    print(f\"\\n{result['message']}\")\n",
    "    print(\"‚ö†Ô∏è  All documents and chunks have been removed\")\n",
    "\n",
    "# Uncomment to clear all data\n",
    "# clear_all_data()\n",
    "\n",
    "print(\"Clear function ready. Use: clear_all_data()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4112904f",
   "metadata": {},
   "source": [
    "## 19. Quick Start Guide\n",
    "\n",
    "### Step-by-Step Instructions:\n",
    "\n",
    "1. **Make sure Ollama is running** with the llama2 model\n",
    "\n",
    "2. **Run cells 1-6** to set up the system\n",
    "\n",
    "3. **Create sample PDFs** (cell 7) or upload your own\n",
    "\n",
    "4. **Upload PDFs** to the system (cell 8)\n",
    "\n",
    "5. **Query documents** using cells 10-14\n",
    "\n",
    "6. **Use the interactive interface** (cell 14) for easy querying\n",
    "\n",
    "### Common Operations:\n",
    "\n",
    "- **List documents**: `controller.get_document_list()`\n",
    "- **Get stats**: `controller.get_stats()`\n",
    "- **Query**: `query_rag_system(\"your question\")`\n",
    "- **Delete document**: `delete_document(\"filename.pdf\")`\n",
    "- **Clear all**: `clear_all_data()`\n",
    "\n",
    "### Tips:\n",
    "\n",
    "- Adjust `top_k` to control number of retrieved chunks\n",
    "- Use different templates: 'default', 'detailed', 'concise'\n",
    "- Filter by specific documents for focused queries\n",
    "- Save state regularly with `controller.rag.save_state()`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9baadeb",
   "metadata": {},
   "source": [
    "## üéâ Congratulations!\n",
    "\n",
    "You now have a fully functional RAG system. Explore the cells above to:\n",
    "- Upload your own PDFs\n",
    "- Query documents with natural language\n",
    "- Manage your document collection\n",
    "- Visualize system statistics\n",
    "\n",
    "**Happy querying! üöÄ**"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
